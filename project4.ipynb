{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: Prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (0.8.3)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-generativeai) (0.6.10)\n",
      "Requirement already satisfied: google-api-core in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-generativeai) (2.23.0)\n",
      "Requirement already satisfied: google-api-python-client in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-generativeai) (2.154.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-generativeai) (2.36.0)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-generativeai) (5.28.3)\n",
      "Requirement already satisfied: pydantic in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-generativeai) (2.9.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-generativeai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-generativeai) (4.11.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.25.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-api-core->google-generativeai) (1.66.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from pydantic->google-generativeai) (2.23.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.68.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.68.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will be exploring google's python wrapper around their ai API\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "#generate your own key on https://aistudio.google.com/apikey\n",
    "gemini_api_key = \"AIzaSyD9gOU2JVUl2dRXm2d_Ys3ADOvFt6ToNnk\"\n",
    "\n",
    "genai.configure(api_key=gemini_api_key)\n",
    "multimodal_model = genai.GenerativeModel(\"gemini-1.5-flash-002\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As a large language model, I don\\'t experience days in the same way humans do. I don\\'t have feelings or personal experiences.  However, I\\'ve been busy processing information and responding to many requests.  So, in a sense, it\\'s been a productive \"day\" for me! How was yours?\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recall that text prompting and image prompting are both supported\n",
    "model_response = multimodal_model.generate_content(\"hi, how was your day?\")\n",
    "model_response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[2, 1]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"harrypotter.webp\")\n",
    "model_response = multimodal_model.generate_content([\"how many male and female actors are in this image? return as list of two numbers: \", img])\n",
    "model_response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at finiteautomata/bertweet-base-sentiment-analysis.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttributeError: module 'ml_dtypes' has no attribute 'float8_e3m4'\n"
     ]
    }
   ],
   "source": [
    "#using your BERT sentiment analysis code from project 3, repeat the process with the uiuc dataset\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\", model=\"finiteautomata/bertweet-base-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common sentiment label is: NEU\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"uiuc.csv\")\n",
    "data['sentiment'] = data['text'].apply(lambda x: pipe(x[:100])[0]['label'])\n",
    "most_common_sentiment = data['sentiment'].mode()[0]\n",
    "print(f\"The most common sentiment label is: {most_common_sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the Gemini API, write a prompt to generate sentiment analysis on the same dataset\n",
    "\n",
    "#make sure to includein the prompt a limit to the type of results (positive, negative, neutral)\n",
    "\n",
    "#compare the sentiment percentages, what do you notice? Does one method overestimate or underestimate the sentiment of the dataset?\n",
    "\n",
    "#find a few cases where their judgement differs, what do you think is the reason for the discrepancy? And which answer do you find more convincing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[43mmultimodal_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m   gemini_sentiments\u001b[38;5;241m.\u001b[39mappend(response\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mparts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/is310/lib/python3.9/site-packages/google/generativeai/generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/is310/lib/python3.9/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:830\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 830\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/is310/lib/python3.9/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/is310/lib/python3.9/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/is310/lib/python3.9/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/is310/lib/python3.9/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/is310/lib/python3.9/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/is310/lib/python3.9/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/is310/lib/python3.9/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mResourceExhausted\u001b[0m: 429 Resource has been exhausted (e.g. check quota).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m     gemini_sentiments\u001b[38;5;241m.\u001b[39mappend(response\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mparts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m      9\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m TooManyRequests:\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     13\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgemini_sentiment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m gemini_sentiments\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Generate sentiment analysis using Gemini API\n",
    "import time\n",
    "from google.api_core.exceptions import TooManyRequests\n",
    "gemini_sentiments = []\n",
    "for text in data['text']:\n",
    "  try:\n",
    "    response = multimodal_model.generate_content(text)\n",
    "    gemini_sentiments.append(response.candidates[0].content.parts[0].text)\n",
    "  except TooManyRequests:\n",
    "    time.sleep(30)\n",
    "    continue\n",
    "\n",
    "data['gemini_sentiment'] = gemini_sentiments\n",
    "\n",
    "bert_sentiment_counts = data['sentiment'].value_counts(normalize=True) * 100\n",
    "gemini_sentiment_counts = data['gemini_sentiment'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"BERT Sentiment Percentages:\")\n",
    "print(bert_sentiment_counts)\n",
    "print(\"\\nGemini Sentiment Percentages:\")\n",
    "print(gemini_sentiment_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrepancies = data[data['sentiment'] != data['gemini_sentiment']]\n",
    "print(\"\\nDiscrepancies between BERT and Gemini sentiment analysis:\")\n",
    "print(discrepancies[['text', 'sentiment', 'gemini_sentiment']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in discrepancies.iterrows():\n",
    "    print(f\"Text: {row['text']}\")\n",
    "    print(f\"BERT Sentiment: {row['sentiment']}\")\n",
    "    print(f\"Gemini Sentiment: {row['gemini_sentiment']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download 10 images from the internet with a feature you're interested in studying. e.g. gender, race, age, action, etc.\n",
    "\n",
    "#ask the model to annotate the images with the features you're interested in studying\n",
    "\n",
    "#choose 2 objective (clear right or wrong answer) questions and ask the model to answer them, like how many people are in the image, or what is the color of the object in the image\n",
    "\n",
    "#choose 2 subjective (open to interpretation) questions and ask the model to answer them, like what is the mood of the person in the image or what race/gender is the person\n",
    "\n",
    "#look through the responses. Is there anything you disagree with? What do you think is the reason for the discrepancy? Would you trust large scale results generated for this annotation? b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_urls = [\n",
    "    \"https://www.alamy.com/happy-multiracial-group-of-diverse-friends-hang-out-in-the-city-young-people-lifestyle-concept-image440070180.html\", \n",
    "    \n",
    "    \"https://www.dreamstime.com/gender-equality-concept-man-woman-equal-balance-diversity-workplace-female-male-employee-having-equal-gender-image279217389\",\n",
    "\n",
    "    \"https://as1.ftcdn.net/v2/jpg/05/64/66/14/1000_F_564661401_NKGJC9hhjv0JGkik4IbWNF6SzkfjUO6S.jpg\",\n",
    "\n",
    "    \"https://www.shutterstock.com/shutterstock/photos/2457469905/display_1500/stock-photo-cheerful-selfie-of-a-group-of-lgbtqia-people-in-a-pride-parade-looking-at-camera-smiling-holding-2457469905.jpg\",\n",
    "\n",
    "    \"https://www.naesp.org/wp-content/uploads/2021/06/Gender-Inclusion-scaled.jpeg\",\n",
    "\n",
    "    \"https://thumbs.dreamstime.com/z/inclusiveness-diversity-equality-concept-abstract-modern-various-people-heads-gender-symbol-equal-sign-equally-raised-230338972.jpg?ct=jpeg\",\n",
    "\n",
    "    \"https://thumbs.dreamstime.com/z/illustration-theme-gender-diversity-people-non-binary-gender-identity-transgender-people-vector-illustration-237363156.jpg?ct=jpeg\",\n",
    "\n",
    "    \"https://www.alamy.com/mirror-reflection-of-non-binary-gender-person-applying-eyebrow-makeup-inside-her-room-focus-on-foreground-beauty-concept-copy-space-image549597247.html\",\n",
    "\n",
    "    \"https://thumbs.dreamstime.com/z/gender-equality-diversity-concept-vector-flat-illustration-blue-pink-human-heads-male-female-transgender-symbol-isolated-214062541.jpg?ct=jpeg\",\n",
    "\n",
    "    \"https://www.shutterstock.com/shutterstock/photos/2445389975/display_1500/stock-vector-gender-equality-concept-men-and-women-character-on-the-scales-for-gender-equality-vector-2445389975.jpg\",\n",
    "]\n",
    "\n",
    "annotations = []\n",
    "for img_url in image_urls:\n",
    "    response = multimodal_model.generate_content([\"Annotate the image with the features of gender: \", img_url])\n",
    "    annotations.append(response.candidates[0].content.parts[0].text)\n",
    "\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_questions = [\n",
    "    \"How many people are in the image?\",\n",
    "    \"What is the color of the object in the image?\"\n",
    "]\n",
    "\n",
    "objective_answers = []\n",
    "for img_url in image_urls:\n",
    "    for question in objective_questions:\n",
    "        response = multimodal_model.generate_content([question, img_url])\n",
    "        objective_answers.append(response.candidates[0].content.parts[0].text)\n",
    "\n",
    "objective_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjective_questions = [\n",
    "    \"What is the mood of the person in the image?\",\n",
    "    \"What race/gender is the person?\"\n",
    "]\n",
    "\n",
    "subjective_answers = []\n",
    "for img_url in image_urls:\n",
    "    for question in subjective_questions:\n",
    "        response = multimodal_model.generate_content([question, img_url])\n",
    "        subjective_answers.append(response.candidates[0].content.parts[0].text)\n",
    "\n",
    "subjective_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Annotations:\")\n",
    "for annotation in annotations:\n",
    "    print(annotation)\n",
    "\n",
    "print(\"\\nObjective Answers:\")\n",
    "for answer in objective_answers:\n",
    "    print(answer)\n",
    "\n",
    "print(\"\\nSubjective Answers:\")\n",
    "for answer in subjective_answers:\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3: Network Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new graph\n",
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_node(1)\n",
    "G.add_nodes_from([2, 3])\n",
    "#can add additional attributes to the nodes\n",
    "G.add_nodes_from([(4, {\"color\": \"red\"}), (5, {\"color\": \"green\"})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can manually add edges too\n",
    "G.add_edge(1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.number_of_edges() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load edges from csv\n",
    "import pandas as pd\n",
    "\n",
    "edges = pd.read_csv(\"got-edges.csv\")\n",
    "\n",
    "G = nx.from_pandas_edgelist(edges, 'Source', 'Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the graph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nx.draw(G, with_labels=True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the density of the graph\n",
    "\n",
    "nx.density(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return highest degree nodes\n",
    "\n",
    "sorted(G.degree, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#make dataframes with nodes and a column for each centrality measure\n",
    "df=pd.DataFrame(list(nx.degree_centrality(G).items()), columns=['node', 'degree'])\n",
    "#add column for betweeness centrality\n",
    "df['betweenness'] = list(nx.betweenness_centrality(G).values())\n",
    "#add column for closeness centrality\n",
    "df['closeness'] = list(nx.closeness_centrality(G).values())\n",
    "#add column for eigenvector centrality\n",
    "df['eigenvector'] = list(nx.eigenvector_centrality(G).values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3a. explore this dataframe, are there huge differences between these types of centrality? What might cause this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate community structure\n",
    "import networkx.algorithms.community as nxcom\n",
    "communities = sorted(nxcom.greedy_modularity_communities(G), key=len, reverse=True)\n",
    "\n",
    "#add community to node features\n",
    "\n",
    "for i, community in enumerate(communities):\n",
    "    for node in community:\n",
    "        df.loc[df.node == node, \"community\"] = i\n",
    "\n",
    "#color nodes by community\n",
    "colors = df.community / df.community.max()\n",
    "\n",
    "nx.draw(G, with_labels=True, node_color=colors, cmap=plt.cm.tab20)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 4: make your own social network. Take either a short excerpt of a novel, tv show, movie, or real life social network you are familiar with. Make a csv modelled off of the got-edges.csv with a Source, Target, and weight column. You need to decide what constitutes an edge and node, but easiest is characters or people connected by their number of interactions. You should manually type this into the csv. Include at least 25 edges\n",
    "\n",
    "What kind of potential issues did you run into while converting it into a graph? Any ambiguities that made it difficult to decide? \n",
    "\n",
    "use either Gephi or NetworkX to calculate node centrality and community features and add a visualization of the graph here. Does it align with your understanding of the media? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "social_network_data = [\n",
    "    ['Source', 'Target', 'Weight'],\n",
    "    ['Olivia', 'Lydia', 5],\n",
    "    ['Olivia', 'Mavis', 5],\n",
    "    ['Olivia', 'Renee', 4],\n",
    "    ['Olivia', 'Carol', 4],\n",
    "    ['Olivia', 'David', 1],\n",
    "    ['Olivia', 'Eugene', 5],\n",
    "    ['Carol', 'Lydia', 3],\n",
    "    ['Carol', 'Renee', 1],\n",
    "    ['Lydia', 'Mavis', 4],\n",
    "    ['Carol', 'Ivan', 2],\n",
    "    ['Carol', 'Judy', 3],\n",
    "    ['Olivia', 'Kayla', 1],\n",
    "    ['Kayla', 'Niaj', 2],\n",
    "    ['Renee', 'Olivia', 3],\n",
    "    ['Olivia', 'Peggy', 1],\n",
    "    ['Peggy', 'Sybil', 2],\n",
    "    ['Peggy', 'Trent', 3],\n",
    "    ['Trent', 'Victor', 1],\n",
    "    ['Renee', 'Walter', 2],\n",
    "    ['Kayla', 'Xander', 3],\n",
    "    ['Olivia', 'Albert', 1],\n",
    "    ['Albert', 'Zara', 2],\n",
    "    ['Albert', 'Alice', 3],\n",
    "    ['Alice', 'David', 1],\n",
    "    ['Renee', 'Eve', 2]\n",
    "]\n",
    "\n",
    "with open('social_network.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(social_network_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_edges = pd.read_csv('social_network.csv')\n",
    "G_social = nx.from_pandas_edgelist(social_edges, 'Source', 'Target', ['Weight'])\n",
    "\n",
    "df_social = pd.DataFrame(list(nx.degree_centrality(G_social).items()), columns=['node', 'degree'])\n",
    "df_social['betweenness'] = list(nx.betweenness_centrality(G_social).values())\n",
    "df_social['closeness'] = list(nx.closeness_centrality(G_social).values())\n",
    "df_social['eigenvector'] = list(nx.eigenvector_centrality(G_social).values())\n",
    "\n",
    "communities_social = sorted(nxcom.greedy_modularity_communities(G_social), key=len, reverse=True)\n",
    "for i, community in enumerate(communities_social):\n",
    "    for node in community:\n",
    "        df_social.loc[df_social.node == node, \"community\"] = i\n",
    "\n",
    "colors_social = df_social.community / df_social.community.max()\n",
    "nx.draw(G_social, with_labels=True, node_color=colors_social, cmap=plt.cm.tab20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
