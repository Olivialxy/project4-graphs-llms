{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: Prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (0.8.3)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-generativeai) (0.6.10)\n",
      "Requirement already satisfied: google-api-core in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-generativeai) (2.23.0)\n",
      "Requirement already satisfied: google-api-python-client in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-generativeai) (2.154.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-generativeai) (2.36.0)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-generativeai) (5.28.3)\n",
      "Requirement already satisfied: pydantic in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-generativeai) (2.9.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-generativeai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-generativeai) (4.11.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.25.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-api-core->google-generativeai) (1.66.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from pydantic->google-generativeai) (2.23.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.68.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.68.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will be exploring google's python wrapper around their ai API\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "#generate your own key on https://aistudio.google.com/apikey\n",
    "gemini_api_key = \"AIzaSyD9gOU2JVUl2dRXm2d_Ys3ADOvFt6ToNnk\"\n",
    "\n",
    "genai.configure(api_key=gemini_api_key)\n",
    "multimodal_model = genai.GenerativeModel(\"gemini-1.5-flash-002\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As a large language model, I don\\'t experience days in the same way humans do. I don\\'t have feelings or personal experiences.  However, I\\'ve been busy processing information and responding to many requests.  So, in a sense, it\\'s been a productive \"day\" for me! How was yours?\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recall that text prompting and image prompting are both supported\n",
    "model_response = multimodal_model.generate_content(\"hi, how was your day?\")\n",
    "model_response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[2, 1]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"harrypotter.webp\")\n",
    "model_response = multimodal_model.generate_content([\"how many male and female actors are in this image? return as list of two numbers: \", img])\n",
    "model_response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at finiteautomata/bertweet-base-sentiment-analysis.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttributeError: module 'ml_dtypes' has no attribute 'float8_e3m4'\n"
     ]
    }
   ],
   "source": [
    "#using your BERT sentiment analysis code from project 3, repeat the process with the uiuc dataset\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\", model=\"finiteautomata/bertweet-base-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"uiuc.csv\")\n",
    "data['sentiment'] = data['text'].apply(lambda x: pipe(x[:100])[0]['label'])\n",
    "most_common_sentiment = data['sentiment'].mode()[0]\n",
    "print(f\"The most common sentiment label is: {most_common_sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the Gemini API, write a prompt to generate sentiment analysis on the same dataset\n",
    "\n",
    "#make sure to includein the prompt a limit to the type of results (positive, negative, neutral)\n",
    "\n",
    "#compare the sentiment percentages, what do you notice? Does one method overestimate or underestimate the sentiment of the dataset?\n",
    "\n",
    "#find a few cases where their judgement differs, what do you think is the reason for the discrepancy? And which answer do you find more convincing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sentiment analysis using Gemini API\n",
    "import time\n",
    "from google.api_core.exceptions import TooManyRequests\n",
    "gemini_sentiments = []\n",
    "for text in data['text']:\n",
    "  try:\n",
    "    response = multimodal_model.generate_content(text)\n",
    "    gemini_sentiments.append(response.candidates[0].content.parts[0].text)\n",
    "  except TooManyRequests:\n",
    "    time.sleep(30)\n",
    "    continue\n",
    "\n",
    "data['gemini_sentiment'] = gemini_sentiments\n",
    "\n",
    "bert_sentiment_counts = data['sentiment'].value_counts(normalize=True) * 100\n",
    "gemini_sentiment_counts = data['gemini_sentiment'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"BERT Sentiment Percentages:\")\n",
    "print(bert_sentiment_counts)\n",
    "print(\"\\nGemini Sentiment Percentages:\")\n",
    "print(gemini_sentiment_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrepancies = data[data['sentiment'] != data['gemini_sentiment']]\n",
    "print(\"\\nDiscrepancies between BERT and Gemini sentiment analysis:\")\n",
    "print(discrepancies[['text', 'sentiment', 'gemini_sentiment']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in discrepancies.iterrows():\n",
    "    print(f\"Text: {row['text']}\")\n",
    "    print(f\"BERT Sentiment: {row['sentiment']}\")\n",
    "    print(f\"Gemini Sentiment: {row['gemini_sentiment']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download 10 images from the internet with a feature you're interested in studying. e.g. gender, race, age, action, etc.\n",
    "\n",
    "#ask the model to annotate the images with the features you're interested in studying\n",
    "\n",
    "#choose 2 objective (clear right or wrong answer) questions and ask the model to answer them, like how many people are in the image, or what is the color of the object in the image\n",
    "\n",
    "#choose 2 subjective (open to interpretation) questions and ask the model to answer them, like what is the mood of the person in the image or what race/gender is the person\n",
    "\n",
    "#look through the responses. Is there anything you disagree with? What do you think is the reason for the discrepancy? Would you trust large scale results generated for this annotation? b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_urls = [\n",
    "    \"https://www.alamy.com/happy-multiracial-group-of-diverse-friends-hang-out-in-the-city-young-people-lifestyle-concept-image440070180.html\", \n",
    "    \n",
    "    \"https://www.dreamstime.com/gender-equality-concept-man-woman-equal-balance-diversity-workplace-female-male-employee-having-equal-gender-image279217389\",\n",
    "\n",
    "    \"https://as1.ftcdn.net/v2/jpg/05/64/66/14/1000_F_564661401_NKGJC9hhjv0JGkik4IbWNF6SzkfjUO6S.jpg\",\n",
    "\n",
    "    \"https://www.shutterstock.com/shutterstock/photos/2457469905/display_1500/stock-photo-cheerful-selfie-of-a-group-of-lgbtqia-people-in-a-pride-parade-looking-at-camera-smiling-holding-2457469905.jpg\",\n",
    "\n",
    "    \"https://www.naesp.org/wp-content/uploads/2021/06/Gender-Inclusion-scaled.jpeg\",\n",
    "\n",
    "    \"https://thumbs.dreamstime.com/z/inclusiveness-diversity-equality-concept-abstract-modern-various-people-heads-gender-symbol-equal-sign-equally-raised-230338972.jpg?ct=jpeg\",\n",
    "\n",
    "    \"https://thumbs.dreamstime.com/z/illustration-theme-gender-diversity-people-non-binary-gender-identity-transgender-people-vector-illustration-237363156.jpg?ct=jpeg\",\n",
    "\n",
    "    \"https://www.alamy.com/mirror-reflection-of-non-binary-gender-person-applying-eyebrow-makeup-inside-her-room-focus-on-foreground-beauty-concept-copy-space-image549597247.html\",\n",
    "\n",
    "    \"https://thumbs.dreamstime.com/z/gender-equality-diversity-concept-vector-flat-illustration-blue-pink-human-heads-male-female-transgender-symbol-isolated-214062541.jpg?ct=jpeg\",\n",
    "\n",
    "    \"https://www.shutterstock.com/shutterstock/photos/2445389975/display_1500/stock-vector-gender-equality-concept-men-and-women-character-on-the-scales-for-gender-equality-vector-2445389975.jpg\",\n",
    "]\n",
    "\n",
    "annotations = []\n",
    "for img_url in image_urls:\n",
    "    response = multimodal_model.generate_content([\"Annotate the image with the features of gender: \", img_url])\n",
    "    annotations.append(response.candidates[0].content.parts[0].text)\n",
    "\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_questions = [\n",
    "    \"How many people are in the image?\",\n",
    "    \"What is the color of the object in the image?\"\n",
    "]\n",
    "\n",
    "objective_answers = []\n",
    "for img_url in image_urls:\n",
    "    for question in objective_questions:\n",
    "        response = multimodal_model.generate_content([question, img_url])\n",
    "        objective_answers.append(response.candidates[0].content.parts[0].text)\n",
    "\n",
    "objective_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjective_questions = [\n",
    "    \"What is the mood of the person in the image?\",\n",
    "    \"What race/gender is the person?\"\n",
    "]\n",
    "\n",
    "subjective_answers = []\n",
    "for img_url in image_urls:\n",
    "    for question in subjective_questions:\n",
    "        response = multimodal_model.generate_content([question, img_url])\n",
    "        subjective_answers.append(response.candidates[0].content.parts[0].text)\n",
    "\n",
    "subjective_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Annotations:\")\n",
    "for annotation in annotations:\n",
    "    print(annotation)\n",
    "\n",
    "print(\"\\nObjective Answers:\")\n",
    "for answer in objective_answers:\n",
    "    print(answer)\n",
    "\n",
    "print(\"\\nSubjective Answers:\")\n",
    "for answer in subjective_answers:\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3: Network Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new graph\n",
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_node(1)\n",
    "G.add_nodes_from([2, 3])\n",
    "#can add additional attributes to the nodes\n",
    "G.add_nodes_from([(4, {\"color\": \"red\"}), (5, {\"color\": \"green\"})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can manually add edges too\n",
    "G.add_edge(1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.number_of_edges() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load edges from csv\n",
    "import pandas as pd\n",
    "\n",
    "edges = pd.read_csv(\"got-edges.csv\")\n",
    "\n",
    "G = nx.from_pandas_edgelist(edges, 'Source', 'Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the graph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nx.draw(G, with_labels=True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the density of the graph\n",
    "\n",
    "nx.density(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return highest degree nodes\n",
    "\n",
    "sorted(G.degree, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#make dataframes with nodes and a column for each centrality measure\n",
    "df=pd.DataFrame(list(nx.degree_centrality(G).items()), columns=['node', 'degree'])\n",
    "#add column for betweeness centrality\n",
    "df['betweenness'] = list(nx.betweenness_centrality(G).values())\n",
    "#add column for closeness centrality\n",
    "df['closeness'] = list(nx.closeness_centrality(G).values())\n",
    "#add column for eigenvector centrality\n",
    "df['eigenvector'] = list(nx.eigenvector_centrality(G).values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3a. explore this dataframe, are there huge differences between these types of centrality? What might cause this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate community structure\n",
    "import networkx.algorithms.community as nxcom\n",
    "communities = sorted(nxcom.greedy_modularity_communities(G), key=len, reverse=True)\n",
    "\n",
    "#add community to node features\n",
    "\n",
    "for i, community in enumerate(communities):\n",
    "    for node in community:\n",
    "        df.loc[df.node == node, \"community\"] = i\n",
    "\n",
    "#color nodes by community\n",
    "colors = df.community / df.community.max()\n",
    "\n",
    "nx.draw(G, with_labels=True, node_color=colors, cmap=plt.cm.tab20)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 4: make your own social network. Take either a short excerpt of a novel, tv show, movie, or real life social network you are familiar with. Make a csv modelled off of the got-edges.csv with a Source, Target, and weight column. You need to decide what constitutes an edge and node, but easiest is characters or people connected by their number of interactions. You should manually type this into the csv. Include at least 25 edges\n",
    "\n",
    "What kind of potential issues did you run into while converting it into a graph? Any ambiguities that made it difficult to decide? \n",
    "\n",
    "use either Gephi or NetworkX to calculate node centrality and community features and add a visualization of the graph here. Does it align with your understanding of the media? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "social_network_data = [\n",
    "    ['Source', 'Target', 'Weight'],\n",
    "    ['Olivia', 'Lydia', 5],\n",
    "    ['Olivia', 'Mavis', 5],\n",
    "    ['Olivia', 'Renee', 4],\n",
    "    ['Olivia', 'Carol', 4],\n",
    "    ['Olivia', 'David', 1],\n",
    "    ['Olivia', 'Eugene', 5],\n",
    "    ['Carol', 'Lydia', 3],\n",
    "    ['Carol', 'Renee', 1],\n",
    "    ['Lydia', 'Mavis', 4],\n",
    "    ['Carol', 'Ivan', 2],\n",
    "    ['Carol', 'Judy', 3],\n",
    "    ['Olivia', 'Kayla', 1],\n",
    "    ['Kayla', 'Niaj', 2],\n",
    "    ['Renee', 'Olivia', 3],\n",
    "    ['Olivia', 'Peggy', 1],\n",
    "    ['Peggy', 'Sybil', 2],\n",
    "    ['Peggy', 'Trent', 3],\n",
    "    ['Trent', 'Victor', 1],\n",
    "    ['Renee', 'Walter', 2],\n",
    "    ['Kayla', 'Xander', 3],\n",
    "    ['Olivia', 'Albert', 1],\n",
    "    ['Albert', 'Zara', 2],\n",
    "    ['Albert', 'Alice', 3],\n",
    "    ['Alice', 'David', 1],\n",
    "    ['Renee', 'Eve', 2]\n",
    "]\n",
    "\n",
    "with open('social_network.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(social_network_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_edges = pd.read_csv('social_network.csv')\n",
    "G_social = nx.from_pandas_edgelist(social_edges, 'Source', 'Target', ['Weight'])\n",
    "\n",
    "df_social = pd.DataFrame(list(nx.degree_centrality(G_social).items()), columns=['node', 'degree'])\n",
    "df_social['betweenness'] = list(nx.betweenness_centrality(G_social).values())\n",
    "df_social['closeness'] = list(nx.closeness_centrality(G_social).values())\n",
    "df_social['eigenvector'] = list(nx.eigenvector_centrality(G_social).values())\n",
    "\n",
    "communities_social = sorted(nxcom.greedy_modularity_communities(G_social), key=len, reverse=True)\n",
    "for i, community in enumerate(communities_social):\n",
    "    for node in community:\n",
    "        df_social.loc[df_social.node == node, \"community\"] = i\n",
    "\n",
    "colors_social = df_social.community / df_social.community.max()\n",
    "nx.draw(G_social, with_labels=True, node_color=colors_social, cmap=plt.cm.tab20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
